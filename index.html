<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Sarc7</title>
  <link rel="stylesheet" href="main.css" />
</head>
<body>

<header class="site-header">
  <h1>Sarc7</h1>
  <p class="subtitle">Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques</p>
</header>

<div class="container">
  <aside class="left-column">
    <section class="box">
      <h2>About the Paper</h2>
      <p>
        Sarc7 introduces a benchmark for sarcasm detection and generation, using seven distinct sarcasm types. Emotion-informed labels and subtype annotations help improve multi-task learning and interpretability. The dataset supports both classification and generation tasks, and integrates psychological theory into NLP modeling.
      </p>
      <a href="data/cleaned_sarcasm_data.json" target="_blank" class="button">ðŸ“¥ Download Dataset</a>
      <a href="docs/paper.pdf" target="_blank" class="button">ðŸ“„ View Paper</a>
    </section>

    <section class="box">
      <h2>Sarc7 Team</h2>
      <ul>
        <li>Lang Xiong</li>
        <li>Raina Gao</li>
        <li>Alyssa Jeong</li>
        <li>Yicheng Fu</li>
        <li>Sean O'Brien</li>
        <li>Vasu Sharma</li>
        <li>Kevin Zhu</li>
      </ul>
    </section>

    <section class="box">
      <h2>Citation</h2>
      <pre>@article{xiong2025sarc7,
  title={Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques},
  author={Xiong, Lang and Gao, Raina and Jeong, Alyssa and Fu, Yicheng and O'Brien, Sean and Sharma, Vasu and Zhu, Kevin},
  journal={arXiv preprint arXiv:2506.00658},
  year={2025}
}</pre>
    </section>
  </aside>

  <main class="right-column">
    <section>
      <h2>Abstract</h2>
      <p>
        We present Sarc7, a sarcasm benchmark with seven fine-grained categories, emotion-aware annotation, and gold/silver standard labels. Sarc7 supports multi-task evaluation across detection and generation, enabling research in sarcasm reasoning.
      </p>
    </section>

    <section>
      <h2>Related Work</h2>
      <p>
        Prior sarcasm datasets focus on binary classification or lack interpretability. Sarc7 expands existing approaches by integrating subtype theory and emotional grounding.
      </p>
    </section>

    <section>
      <h2>Benchmark Features</h2>
      <ul>
        <li>7 sarcasm subtypes</li>
        <li>Emotion-informed span annotations</li>
        <li>Multi-reference sarcastic generations</li>
        <li>Gold and silver labels</li>
      </ul>
      <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Simple_Matrix.svg/512px-Simple_Matrix.svg.png" alt="Benchmark Example" />
    </section>

    <section>
      <h2>Methodology</h2>
      <p>
        We use transformer models (BERT, RoBERTa) for sarcasm detection and generation. Emotion and subtype embeddings are jointly trained in a multi-task framework. We also test generation with conditional decoding and style transfer.
      </p>
    </section>

    <section>
      <h2>Results</h2>
      <p>
        Emotion-informed models significantly outperform baselines in sarcasm subtype detection and generation. Performance improvements range from 5â€“12% on subtype F1 and BLEU for generation.
      </p>
      <img src="https://upload.wikimedia.org/wikipedia/commons/1/14/Bar_chart_icon.svg" alt="Results Graph" />
    </section>
  </main>
</div>

<footer>
  <p>Â© 2025 Sarc7 Team Â· <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0</a></p>
</footer>

</body>
</html>
